\chapter{Dataset}
\label{ch:dataset}

How do we capture large and annotated datasets to train an \gls{ai} model at scale? What is an annotation, and how can we constrain them? These are important questions when supplying data to train graphics-based \glspl{ai}. In this chapter, we discuss a theoretical data tagging metamodel that enables us to concisely describe the architecture of how quality labelled data is captured for these purposes. Additionally, we discuss a partial implementation of this metamodel which we have used to gather our training dataset.

\input{mainmatter/dataset/architecture.tex}
\input{mainmatter/dataset/process.tex}

\subsection{Metamodel Grammar}

\todo{Develop metamodel grammar}

\section{Data Augmentation}

\section{Argus}

% motivation
% methodology
% a layered data tagging metamodel
%% definitions (data structures)
%% layering
%% workflows
% implementation
%% findings (productivity)
%% quality
